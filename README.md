# Ya-disk-contest

Сервис с REST API, реализующий бэкенд для веб-сервиса хранения файлов, аналогичный сервису Яндекс Диск.
Позволяет пользователям загружать и обновлять информацию о файлах и папках.
Вступительное [задание](docs/Task.md) в Осеннюю Школу Бэкенд Разработки Яндекса 2022.

## Описание

---
Приложение упаковано в Docker-контейнер. Внутри Docker-контейнера доступны две команды: `disk-db` — утилита для управления состоянием базы данных и `disk-api` — утилита для запуска REST API сервиса.

Сервис в учебных целях написан на двух веб-фреймворках: `aiohttp` и `fastapi`. Для запуска использовать соответственно команды `disk-api aiohttp` и `disk-api fastapi`.

## Использование с Docker

---
* Создать сеть:
  ```sh
  docker network create api-net
  ```
  
  Запустить контейнер с Postgres в сети:
  ```shell
  docker run --rm -d \
      --name=db \
      --network api-net \
      -e POSTGRES_USER=user \
      -e POSTGRES_PASSWORD=psw \
      -e POSTGRES_DB=disk \
      -p 5432:5432 \
      postgres
  ```
  
  Применить миграции (хост - имя контейнера с Postgres):
  ```shell
  docker run -it --network api-net \
      -e DISK_PG_DSN=postgresql://user:psw@db/disk \
      r0van/ya-disk-contest disk-db upgrade head
  ```
  
  Запустить REST API сервис локально на порту 8081:
  ```shell
  docker run -it --network api-net -p 8081:8081 \
      -e DISK_PG_DSN=postgresql://user:psw@db/disk \
      r0van/ya-disk-contest
  ```

* Или использовать docker-compose [файл](docker-compose.yml):

  ```shell
  docker-compose up db -d
  docker-compose up api -d
  ```
  И также применить миграции внутри контейнера с приложением. 

Все доступные опции запуска любой команды можно получить с помощью аргумента `--help`:
```shell
docker run r0van/ya-disk-contest disk-db --help
docker run r0van/ya-disk-contest disk-api --help
docker run r0van/ya-disk-contest disk-api aiohttp --help
docker run r0van/ya-disk-contest disk-api fastapi --help
```



## Разработка

---

#### 1. Создать и активировать виртуальное окружение, установить основные и dev зависимости:

  ```shell
  python -m venv env
  source env/bin/activate
  pip install -U pip
  pip install -Ue '.[dev]'
  ```
#### 2. Запустить контейнер с Postgres:
  ```shell
  docker run --rm --detach --name=db \
    --env POSTGRES_USER=user \
    --env POSTGRES_PASSWORD=psw \
    --env POSTGRES_DB=disk \
    --publish 5432:5432 postgres
  ```
#### 3. Применить миграции и запустить приложение:
  ```shell
  disk-db upgrade head
  disk-api fastapi # или disk-api aiohttp
  ```
  Все доступные опции запуска любой команды можно получить с помощью аргумента `--help`.
  
  Опции для запуска можно указывать как аргументами командной строки, так и переменными окружения с префиксом `DISK` (например: вместо аргумента `--api-port` можно воспользоваться `DISK_API_PORT`).

**После запуска команд приложение начнет слушать запросы на http://0.0.0.0:8081.**

### Тестирование
  Тесты для этого проекта находятся в папке `/tests`.

  Запуск тестов с приложением на `fastapi`:
```shell
pytest
```
  Запуск тестов с приложением на `aiohttp`:
```shell
pytest --aiohttp
```
  Запуск тестов с флагом `slow`:
```shell
pytest --slow # pytest --aiohttp --slow
```

### Нагрузочное тестирование
  Для нагрузочного тестирования используется [locust](https://locust.io/).
  ```shell
  locust
  ```
  После выполнения этой команды станет доступен веб-интерфейс по адресу http://localhost:8089.
  
  **Рекомендуется использовать [несколько воркеров](https://docs.locust.io/en/stable/running-distributed.html).**

## Заметки

---


* Если изучить типичный UI облачных хранилищ, то можно заключить, что в одном импорте у всех "верхних" узлов (родителя которых нет в этом импорте) будет один общий родитель. Также в одном импорте не может быть одновременно новых и перемещенных уже существующих узлов. Однако в задании нет уточнений на правила (кроме отсутствия кольцевых ссылок) и сложность импортов, поэтому реализована логика, допускающая импорт любой сложности.
  
  
* В одном импорте одновременно может быть:
  - Несколько новых элементов с разными родительскими папками.
  - Несколько перемещенных обновляемых элементов из любых папок. 
  - Родителями новых и обновляемых элементов могут быть новые папки из этого импорта или папки, обновляемые в этом импорте, или любые существующие в хранилище папки (при соблюдении условии отсутствия кольцевых ссылок).  
  - Следующая ситуация: есть "папка-1" и ее дочерняя (на прямую или через несколько папок) "папка-2". "Папка-2" перемещается в другую ветку или в ту же, но выше "папки-1", а "папка-1" в этом же импорте перемещается в "папку-2" или в её дочернюю папку.
  - Вообще любые по сложности ситуации, при которых не возникает кольцевых ссылок.


* При этом я руководствовался целью сделать как можно меньше рекурсивных запросов к БД в одном импорте и избежать излишнего переноса данных из БД в приложение и обратно. Вся обработка происходит на стороне Postgres с помощью рекурсивных запросов. На стороне Python выполняется только сортировка импортируемых папок, чтобы не добавить дочернюю папку раньше родительской, и формирование вложенной структуры json для запроса **GET /nodes/{id}**.


* Схема БД состоит из 6 таблиц:

  ![схема бд](/docs/db-schema.png)

  * Рассматривалось несколько вариантов схемы:
    1. Полностью нормализованная с таблицами **imports**, **files**, **folders**, размер папки вычисляется при каждом GET запросе, но не хранится в БД. Первичный ключ для таблиц элементов формируется из полей id и import_id.
    2. Аналогичная первой, но с одной таблицей элементов **items**.
    3. С сохранением размеров папок в записях таблицы и их вычислением при каждом импорте.
    4. С сохранением размеров папок и двумя дополнительными таблицами истории элементов. Первичный ключ для таблиц элементов по полю id.
    5. Аналогичная схеме выше с дополнительным полем root_id в таблицах элементов, чтобы получать по нему рекомендательную блокировку для обновляемого дерева папок.

    <sub>*В начале разработки я остановился на четвертом варианте. От первого варианта было принято решение отказаться, так как GET запросы становятся тяжёлыми, а по заданию их RPS выше на порядок. Уже на завершающем этапе работы над проектом я понял, что, возможно, это лучший вариант, так как он не подвержен состоянию гонки при конкурентных импортах. Но всё же запрос истории изменений папки в этом варианте очень тяжёлый, так как нужно вычислять размер папки для каждой её версии, и само определение количества версий становится нетривиальной задачей.*</sub>

    <sub>*Таблицы истории добавлены, чтобы не выбирать для каждого элемента последнюю версию в запросе **GET /nodes/{id}**.*</sub>
  
## Вопросы

---
* Выбор инструментов и технологий для решения задания? 

  <sub>*Я провел небольшой ресёрч на старте выполнения проекта. Но всё же были цели сдать проект в срок и потренироваться использовать технологии, о которых что-то слышал и видел в вакансиях для джунов.*</sub>


* Какая схема БД лучше подходит для этого задания?


* Следует ли считать папку обновлённой, если при изменении её дочерних элементов размер папки остался прежним? (в текущей реализации папка считается обновленной в этом случае)


* Что возвращать в **GET /updates**: все обновления каждого файла в течение суток или только последнюю версию? Я сделал второй вариант, изменить на первый несложно.
 

* Есть ли смысл создать int primary key для элемента? Ведь всё равно нужно делать индекс по строковому id и искать элементы по нему? Может вообще использовать UUID (хотя в задании сказано, что id это строка)?


* Что делать, если два запроса с импортом данных пришли практически одновременно, а порядок их обработки важен? Тесты показывают, что запросы с интервалом около 30 мс могут обрабатываться в случайном порядке. Мой костыль - это таблица очереди в БД и [QueueWorker](disk/utils/queue_worker.py), позволяющий нескольким воркерам приложения работать с таблицей очереди согласованно. Я понимаю, что это плохая реализация, у меня есть предположения, где искать решения, но я решил отложить этот вопрос до поры.

# Ya-disk-contest

Сервис с REST API, реализующий бэкенд для веб-сервиса хранения файлов, аналогичный сервису Яндекс Диск.
Позволяет пользователям загружать и обновлять информацию о файлах и папках.
Вступительное [задание](docs/Task.md) в Осеннюю Школу Бэкенд Разработки Яндекса 2022.

## Что внутри?

---
Приложение упаковано в Docker-контейнер. Внутри Docker-контейнера доступны две команды: `cloud-db` — утилита для управления состоянием базы данных и `cloud-api` — утилита для запуска REST API сервиса.

Сервис реализован с помощью двух веб фреймворков: `aiohttp` и `fastapi`. Для запуска использовать соответственно команды `cloud-api aiohttp` и `cloud-api fastapi`.

## Как использовать?

---
* Создать сеть:
  ```shell
  docker network create api-net
  ```
  
  Запустить контейнер с Postgres в сети:
  ```shell
  docker run --rm -d \
      --name=db \
      --network api-net \
      -e POSTGRES_USER=user \
      -e POSTGRES_PASSWORD=psw \
      -e POSTGRES_DB=cloud \
      -p 5432:5432 \
      postgres
  ```
  
  Применить миграции (хост - имя контейнера с Postgres):
  ```shell
  docker run -it --network api-net \
      -e CLOUD_PG_DSN=postgresql://user:psw@db/cloud \
      r0van/enrollment_autumn_2022 cloud-db upgrade head
  ```
  
  Запустить REST API сервис локально на порту 8081:
  ```shell
  docker run -it --network api-net -p 8081:8081 \
      -e CLOUD_PG_DSN=postgresql://user:psw@db/cloud \
      r0van/ya-disk-contest
  ```

* Или использовать docker-compose [файл](docker-compose.yml):

  ```shell
  docker-compose up db -d
  docker-compose up api -d
  ```
  И также применить миграции внутри контейнера с приложением. 

Все доступные опции запуска любой команды можно получить с помощью аргумента `--help`:
```shell
$ docker run r0van/enrollment_autumn_2022 cloud-db --help
$ docker run r0van/enrollment_autumn_2022 cloud-api --help
```



## Разработка

---

### 1. Создать виртуальное окружение и установить зависимости:

  ```shell
  # создаем новое окружение
  $ python3.10 -m venv env
  # активируем окружение
  $ source env/bin/activate
  # обновляем pip
  $ pip install -U pip
  # устанавливаем основные и dev зависимости(см. optional-dependencies в pyproject.toml)
  $ pip install -Ue '.[dev]'
  ```
### 2. Запустить контейнер с Postgres:
  ```shell
  $ docker stop db || true
  $ docker run --rm --detach --name=db \
      --env POSTGRES_USER=user \
      --env POSTGRES_PASSWORD=psw \
      --env POSTGRES_DB=cloud \
      --publish 5432:5432 postgres
  ```
### 3. Применить миграции и запустить приложение:
  ```shell
  $ cloud-db upgrade head
  $ cloud-api
  ```
  Все доступные опции запуска любой команды можно получить с помощью аргумента `--help`.
  
  Опции для запуска можно указывать как аргументами командной строки, так и переменными окружения с префиксом `CLOUD` (например: вместо аргумента `--api-port` можно воспользоваться `CLOUD_API_PORT`).

**После запуска команд приложение начнет слушать запросы на http://0.0.0.0:8081.**

### 4. Нагрузочное тестирование.
  Для нагрузочного тестирования используется [locust](https://locust.io/).
  ```shell
  $ locust
  ```
  После выполнения этой команды (в активированной виртуальной среде) станет доступен веб-интерфейс по адресу http://localhost:8089.
  
  **Рекомендуется использовать [несколько воркеров](https://docs.locust.io/en/stable/running-distributed.html).**

## Заметки

---


* Если смотреть на типичный UI облачных хранилищ, то логично предположить, что в одном импорте у всех "верхних" узлов (то-есть узлов, родителя которых нет в этом импорте) будет один общий родитель. Также в одном импорте не может быть одновременно новых и перемещенных уже существующих узлов. Однако в задании нет уточнений на правила (кроме отсутствия кольцевых ссылок) и сложность импортов, поэтому реализована логика в соответствии с возможностью импорта любой сложности.
  
  
* В одном импорте одновременно может быть:
  - Несколько новых элементов с разными родительскими папками.
  - Несколько перемещенных обновляемых элементов из любых папок. 
  - Родителями новых и обновляемых элементов могут быть новые папки из этого импорта или папки, обновляемые в этом импорте, или любые существующие в хранилище папки (при соблюдении условии отсутствия кольцевых ссылок).  
  - Следующая ситуация: есть "папка-1" и ее дочерняя (на прямую или через несколько папок) "папка-2". "Папка-2" перемещается в другую ветку или в ту же, но выше "папки-1", а "папка-1" в этом же импорте перемещается в "папку-2" или в её дочернюю папку.
  - Вообще любые по сложности ситуации, при которых не возникает кольцевых ссылок.


* При этом было стремление сделать как можно меньше запросов к БД в одном импорте и не таскать излишние данные туда-сюда из БД в приложение и обратно. Вся обработка происходит на стороне Postgres с помощью рекурсивных запросов. На стороне Python выполняется только сортировка импортируемых папок, чтобы не добавить дочернюю папку раньше родительской, и формирование вложенной структуры json для метода **GET /nodes/{id}**.


* Схема БД состоит из 5 таблиц:
  ![схема бд](/docs/db-schema.png)

  * Рассматривалось несколько вариантов схемы. От полностью нормализованного, в котором размер папки вычисляется при каждом GET запросе, но не хранится в БД, было принято решение отказаться, так как по заданию RPS на GET запросы выше на порядок. Поэтому размеры папок вычисляются при каждом импорте и хранятся в записях таблицы folders. 
  * Решение разделить таблицы элементов по типу элемента, кажется не принесло ничего, кроме трудностей реализации.
  * Также в нормализованной схеме был вариант формировать первичный ключ для таблиц из полей id и import_id, и при обновлении элемента лишь добавлять новые записи в таблицы, а не переносить записи в таблицы историй, но кажется, что это может плохо сказаться на производительности (ведь каждый раз при поиске элемента по id нужно будет выбирать запись элемента с максимальным import_id). Кроме того, в этом варианте есть парочка запутанных моментов в реализации обработчиков.
  
## Вопросы

---
* Выбор инструментов и технологий для решения задания? 

  <sub>*Я провел небольшой ресёрч на старте выполнения проекта. Но всё же были цели сдать проект в срок и потренироваться использовать технологии, о которых что-то слышал и видел в вакансиях для джунов. Графовые БД?*</sub>


* Какая схема БД лучше подходит для этого задания?


* Следует ли считать элемент обновлённым, если в новом импорте все поля для него идентичны (т.е. по сути изменилось только поле date)? 


* Следует ли считать папку обновлённой, если при изменении её дочерних элементов размер папки остался прежним?


* Что возвращать в **GET /updates**: все обновления каждого файла в течение суток или только последнюю версию? Я сделал второй вариант, изменить на первый несложно.
 

* Есть ли смысл создать int primary key для элемента? Ведь всё равно нужно делать индекс по строковому id и искать элементы по нему? Может вообще использовать UUID (хотя в задании сказано, что id это строка)?


* В текущей реализации с произвольными импортами (см. заметки) в методе **GET /imports** нужно блокировать все обновляемые ветки. Я пока не разобрался, как это правильно реализовать. На данный момент advisory lock есть только в тестах (в нагрузочном тестировании это не создает проблем, так как у каждого "пользователя" locust как бы своё хранилище).


* Что делать, если два импорта пришли практически одновременно? В тестах я проверял, что при разнице по времени запросов порядка 30 мс обработчики для этих импортов вызываются в случайном порядке. Advisory lock здесь не помогает. Мой костыль (реализован только в тестах) - это очередь на стороне Python, что приводит по сути к синхронной обработке импортов. Если принять, что в импортах внешний родитель у всех элементов один (см. заметки), то, по идее, можно реализовать это без больших потерь производительности. Можно лучше?


* В задании есть требования по RPS, но без уточнений не совсем понятно, как их проверять. Какого объема импорты предполагаются? При каком количестве записей о файлах и папках хранящихся в БД?

## Планы

---
* Разобраться с состоянием гонки (возможно, написать версию приложения с "простыми" импортами).
* Деплой с помощью Ansible.
* Попробовать FastAPI.
* ORM SQLAlchemy 
* Проверить секционирование таблиц для увеличения производительности.